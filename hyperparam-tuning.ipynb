{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"provenance":[{"file_id":"https://github.com/timeseriesAI/tsai/blob/master/tutorial_nbs/05_TS_archs_comparison.ipynb","timestamp":1706877844902}],"gpuType":"T4"},"accelerator":"GPU","language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7545810,"sourceType":"datasetVersion","datasetId":4394465,"isSourceIdPinned":false}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installing dependencies","metadata":{"id":"9OFZOw6-Gdlc"}},{"cell_type":"code","source":"stable = True # Set to True for latest pip version or False for main branch in GitHub\n!pip install {\"tsai -U\" if stable else \"git+https://github.com/timeseriesAI/tsai.git\"} >> /dev/null","metadata":{"id":"JCZN0DQYhgXk","executionInfo":{"status":"ok","timestamp":1706962535417,"user_tz":-360,"elapsed":9636,"user":{"displayName":"S.M. Hozaifa Hossain","userId":"03039388269630313999"}},"execution":{"iopub.status.busy":"2024-02-05T05:20:49.098871Z","iopub.execute_input":"2024-02-05T05:20:49.099816Z","iopub.status.idle":"2024-02-05T05:21:01.966598Z","shell.execute_reply.started":"2024-02-05T05:20:49.099779Z","shell.execute_reply":"2024-02-05T05:21:01.965401Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom scipy.interpolate import interp1d\nfrom sklearn.gaussian_process.kernels import RBF\nimport torch\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nfrom tsai.all import *\nimport sklearn.metrics as skm\nfrom IPython.display import clear_output\nimport copy\nmy_setup()\nwarnings.simplefilter('ignore')","metadata":{"id":"Wc3nK-ZynhUK","executionInfo":{"status":"ok","timestamp":1706962545925,"user_tz":-360,"elapsed":10517,"user":{"displayName":"S.M. Hozaifa Hossain","userId":"03039388269630313999"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c6b549b-2d87-4382-a6aa-87decc63a03e","execution":{"iopub.status.busy":"2024-02-05T05:21:01.969211Z","iopub.execute_input":"2024-02-05T05:21:01.969600Z","iopub.status.idle":"2024-02-05T05:21:02.003150Z","shell.execute_reply.started":"2024-02-05T05:21:01.969561Z","shell.execute_reply":"2024-02-05T05:21:02.002258Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"os              : Linux-5.15.133+-x86_64-with-glibc2.31\npython          : 3.10.13\ntsai            : 0.3.8\nfastai          : 2.7.13\nfastcore        : 1.5.29\ntorch           : 2.1.2\ndevice          : 1 gpu (['Tesla P100-PCIE-16GB'])\ncpu cores       : 2\nthreads per cpu : 2\nRAM             : 31.36 GB\nGPU memory      : [16.0] GB\n","output_type":"stream"}]},{"cell_type":"code","source":"X_rand = np.load(\"/kaggle/input/np-arrays/X_rand_samp.npy\")\ny_wtd = np.load(\"/kaggle/input/np-arrays/y_wtd_samp.npy\")\nX_wtd=np.load('/kaggle/input/np-arrays/X_wtd_samp.npy')\ny_rand= np.load('/kaggle/input/np-arrays/y_rand_samp.npy')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T05:21:02.004400Z","iopub.execute_input":"2024-02-05T05:21:02.004725Z","iopub.status.idle":"2024-02-05T05:21:02.018582Z","shell.execute_reply.started":"2024-02-05T05:21:02.004693Z","shell.execute_reply":"2024-02-05T05:21:02.017757Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Further split the training set into train and validation sets (75/25 split)\nX_train, X_val, y_train, y_val = train_test_split(X_wtd, y_wtd, test_size=0.2)\n# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T05:21:02.021036Z","iopub.execute_input":"2024-02-05T05:21:02.021366Z","iopub.status.idle":"2024-02-05T05:21:02.029240Z","shell.execute_reply.started":"2024-02-05T05:21:02.021334Z","shell.execute_reply":"2024-02-05T05:21:02.028337Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Initializing data","metadata":{"id":"aKvYvlgx5nU5"}},{"cell_type":"code","source":"bs = 16\nX, y, splits = combine_split_data([X_train, X_test], [y_train, y_test])\ntfms  = [None, [Categorize()]]\ndsets = TSDatasets(X, y, tfms=tfms, splits=splits)\ndls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs])\n","metadata":{"id":"NAxbFp1J75W3","executionInfo":{"status":"ok","timestamp":1706962549957,"user_tz":-360,"elapsed":4,"user":{"displayName":"S.M. Hozaifa Hossain","userId":"03039388269630313999"}},"execution":{"iopub.status.busy":"2024-02-05T05:21:02.030527Z","iopub.execute_input":"2024-02-05T05:21:02.031208Z","iopub.status.idle":"2024-02-05T05:21:02.317925Z","shell.execute_reply.started":"2024-02-05T05:21:02.031175Z","shell.execute_reply":"2024-02-05T05:21:02.317007Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Finding a good initial learning rate for the model before tuning","metadata":{"id":"7zVojLWI5qzm"}},{"cell_type":"code","source":"# learn = Learner(dls, model_to_train(dls.vars, dls.c, dls.len), metrics=[F1Score(average='macro')])\n# learn.lr_find()","metadata":{"id":"lPw2SYO-uYkm","execution":{"iopub.status.busy":"2024-02-05T05:21:02.325331Z","iopub.execute_input":"2024-02-05T05:21:02.325637Z","iopub.status.idle":"2024-02-05T05:21:02.378689Z","shell.execute_reply.started":"2024-02-05T05:21:02.325611Z","shell.execute_reply":"2024-02-05T05:21:02.376906Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m learn \u001b[38;5;241m=\u001b[39m Learner(dls, \u001b[43mmodel_to_train\u001b[49m(dls\u001b[38;5;241m.\u001b[39mvars, dls\u001b[38;5;241m.\u001b[39mc, dls\u001b[38;5;241m.\u001b[39mlen), metrics\u001b[38;5;241m=\u001b[39m[F1Score(average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m      2\u001b[0m learn\u001b[38;5;241m.\u001b[39mlr_find()\n","\u001b[0;31mNameError\u001b[0m: name 'model_to_train' is not defined"],"ename":"NameError","evalue":"name 'model_to_train' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"### Hyperparam tuning of the MODEL","metadata":{"id":"BQqpfMmT528L"}},{"cell_type":"code","source":"# Use best initial epochs and max_lr\nepochs = 25\nmax_lr = 1e-3","metadata":{"execution":{"iopub.status.busy":"2024-02-05T06:02:41.925748Z","iopub.execute_input":"2024-02-05T06:02:41.926666Z","iopub.status.idle":"2024-02-05T06:02:41.934091Z","shell.execute_reply.started":"2024-02-05T06:02:41.926619Z","shell.execute_reply":"2024-02-05T06:02:41.933069Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from fastai.callback.tracker import *\nearly_stopping = EarlyStoppingCallback(patience=3, min_delta=0.05)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T06:02:44.666425Z","iopub.execute_input":"2024-02-05T06:02:44.666749Z","iopub.status.idle":"2024-02-05T06:02:44.671497Z","shell.execute_reply.started":"2024-02-05T06:02:44.666721Z","shell.execute_reply":"2024-02-05T06:02:44.670475Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"* Conclusions from \n* model1: RNNPlus\n* model2: RNNAttention\n* https://docs.google.com/document/d/1skeTIoSMsVwEUPVI6HAi7rVfM1dVMvA0BYECeTmwUvQ/edit?usp=sharing\n* LSTM, GRU not used as RNN showed better results\n","metadata":{}},{"cell_type":"code","source":"# Focus on RNNPlus hyperparameters, ignore irrelevant ones\nmodel2 = RNNPlus\nmax_lr = 2.12e-4\nseq_len = [  # Set based on your sequence length or strategy\n    # ... (e.g., different fixed lengths or truncation methods)\n]\nhidden_size = [1024]  # Experiment with different sizes\nn_layers = [4]  # Try 1-3 layers\nrnn_dropout = [0.1, 0.2, 0.3]  # Starting points for dropout\n\narchs = []\nfor out_classes in c_out:\n    for length in seq_len:\n      for h_size in hidden_size:\n        for layers in n_layers:\n          for lr in learning_rate:\n            for dropout in rnn_dropout:\n              archs.append((model_to_train, {\n#                 'c_in': your_input_channels,  # Set based on your data shape\n#                 'c_out': out_classes,\n                'seq_len': length,\n                'hidden_size': h_size,\n                'n_layers': layers,\n                'rnn_dropout': dropout,\n                # Ignore other less important parameters for now\n              }))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# {'d_model': 64, 'depth': 8, 'lstm_dropout': 0.1, 'dropout': 0.1, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}\t5970213\t0.427612\t0.422031\t0.758592\t23\t25\t0.001\n# 1\tTSSequencerPlus\t{'d_model': 64, 'depth': 2, 'lstm_dropout': 0.3, 'dropout': 0.2, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}\t\n\nmodel3= TSSequencerPlus\nd_model = [32, 64, 128]\ndepth = [2, 4, 8]\nlstm_dropout = [0.1, 0.2, 0.3]\ndropout = [0.1, 0.2, 0.3]\nmlp_ratio = [2, 4]\narchs = []\nfor dimension in d_model:\n    for transfblock in depth:\n      for tfr_dropout in dropout:\n        for lstmdropout in lstm_dropout:\n          for mlp_dim_ratio in mlp_ratio:\n            archs.append((model_to_train, {\n              'd_model': dimension,  # Add d_model for embedding dimension\n              'depth': transfblock,  # Add depth for number of transformer blocks\n              'lstm_dropout': lstmdropout,\n              'dropout': tfr_dropout,  # Use tfr_dropout for transformer dropout\n              'mlp_ratio': mlp_dim_ratio,\n              'n_layers': rnn_layers,\n              'hidden_size': hidden_size,\n              'use_pe': True,  # Enable positional encoding by default\n              # Remove commented-out lines for unused parameters\n            }))","metadata":{"execution":{"iopub.status.busy":"2024-02-05T06:02:42.416571Z","iopub.execute_input":"2024-02-05T06:02:42.417422Z","iopub.status.idle":"2024-02-05T06:02:42.423566Z","shell.execute_reply.started":"2024-02-05T06:02:42.417383Z","shell.execute_reply":"2024-02-05T06:02:42.422513Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"\n# Focus on InceptionTime hyperparameters, remove unnecessary sections\nmodel4 = InceptionTime\nnf = [32, 64, 128]\nnb_filters = [16, 32, 64]\nks = [3, 5, 7]\nbottleneck = [True, False]  # Experiment with both options\n\narchs = []\nfor f in nf:\n    for num_filters in nb_filters:\n      for kernel_size in ks:\n        for use_bottleneck in bottleneck:\n          archs.append((model_to_train, {\n            'c_in': 1,  # Assuming grayscale keypoint data\n            'c_out': len(your_activity_classes),  # Replace with actual number of activities\n            'nf': f,\n            'nb_filters': num_filters,\n            'ks': kernel_size,\n            'bottleneck': use_bottleneck,\n          }))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5 = TransformerRNNPlus\nd_model = [32, 64, 128]\nnhead = [4, 8, 16]\nnum_encoder_layers = [1, 2, 4]\ndim_feedforward = [2 * d for d in d_model]  # Based on d_model values\ndropout = [0.1, 0.2, 0.3]\nnum_rnn_layers = [1, 2, 3]  # Adjust if handling longer sequences\n\narchs = []\nfor d in d_model:\n    for h in nhead:\n      for e in num_encoder_layers:\n        for ff in dim_feedforward:\n          for dr in dropout:\n            for rnn in num_rnn_layers:\n              archs.append((model_to_train, {\n                'c_in': 1,  # Assuming grayscale keypoint data\n                'c_out': len(your_activity_classes),\n                'd_model': d,\n                'nhead': h,\n                'num_encoder_layers': e,\n                'dim_feedforward': ff,\n                'dropout': dr,\n                'num_rnn_layers': rnn,\n              }))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model6 = TSTPlus\nn_layers = [2, 4, 6]\nd_model = [64, 128, 256]\nn_heads = [4, 8, 16]\nd_ff = [d * 2 for d in d_model]  # Start with d_ff = 2 * d_model\nattn_dropout = [0.1, 0.2, 0.3]\ndropout = [0.1, 0.2, 0.3]\nmax_seq_len = [  # Adjust based on your data's average/max sequence length\n    min(512, int(np.mean(your_sequence_lengths))),\n    min(512, np.max(your_sequence_lengths))\n]\nlearn_pe = [True, False]  # Experiment with both options\n\narchs = []\nfor layers in n_layers:\n    for dim in d_model:\n      for heads in n_heads:\n        for use_dropout in attn_dropout:\n          for lstm_dropout in dropout:\n            archs.append((model_to_train, {\n              'n_layers': layers,\n              'd_model': dim,\n              'n_heads': heads,\n              'd_ff': d_ff[d_model.index(dim)],\n              'attn_dropout': use_dropout,\n              'dropout': lstm_dropout,\n              'max_seq_len': max_seq_len[0],  # Consider using both lengths later\n              'learn_pe': learn_pe[0],  # Consider both True/False later\n              # Set other parameters based on your data and preferences\n            }))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model7 = PatchTST # Assuming you want to keep PatchTST\nn_layers = [2, 4, 6]  # Experiment with more layers based on resources\nd_model = [128, 256, 512]  # Adjust based on data complexity and memory\npatch_len = [8, 16, 32]  # Consider activity duration and sequence length\nstride = [1, 2, 4]  # Keep stride smaller than patch_len\nn_heads = [4, 8, 16]  # Start with lower values and increase if needed\ndropout = [0.1, 0.2, 0.3]  # Regularization for overfitting prevention\n\narchs = []\nfor layers in n_layers:\n    for dim in d_model:\n      for p_len in patch_len:\n        for p_stride in stride:\n          for heads in n_heads:\n            for dr in dropout:\n              archs.append((model_to_train, {\n                'n_layers': layers,\n                'd_model': dim,\n                'patch_len': p_len,\n                'stride': p_stride,\n                'n_heads': heads,\n                'dropout': dr,\n                # Other parameters with default or less impact values\n              }))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model8 = SequentialRNN\nmodel9 = ResNet","metadata":{}},{"cell_type":"code","source":"model_to_train=model3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame to store results\nresults = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'f1_score', 'time', 'epochs', 'max_lr'])\nmodel = create_model(model_to_train, dls=dls, **(archs[0][1]))\nfor i, (arch, k) in enumerate(archs):\n    model_copy = copy.deepcopy(model)  \n\n    print(model.__class__.__name__, '\\n', k)\n    learn = Learner(dls, model_copy, metrics=[F1Score(average='macro')], \n                   cbs=[early_stopping,]\n                   )\n    start = time.time()\n    learn.fit_one_cycle(epochs, max_lr)  # Use correct epochs and lr for each iteration\n    elapsed = time.time() - start\n    \n    vals = learn.recorder.values[-1]\n    results.loc[i] = [arch.__name__, k, count_parameters(model), vals[0], vals[1], vals[2], int(elapsed), epochs, max_lr]\n    results.sort_values(by='f1_score', ascending=False, kind='stable', ignore_index=True, inplace=True)\n    clear_output()\n    display(results.head(10))\n\n# # Sort results\n# results.sort_values(by='f1_macro', inplace=True, ascending=False)\n\n# # Show top results\n# display(results.head())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"jxWaZkmZshBu","outputId":"0fb5688c-6166-44d9-f158-1424ea54df94","executionInfo":{"status":"ok","timestamp":1706964370669,"user_tz":-360,"elapsed":633885,"user":{"displayName":"S.M. Hozaifa Hossain","userId":"03039388269630313999"}},"scrolled":true,"execution":{"iopub.status.busy":"2024-02-05T06:03:04.585126Z","iopub.execute_input":"2024-02-05T06:03:04.585538Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"              arch  \\\n0  TSSequencerPlus   \n1  TSSequencerPlus   \n2  TSSequencerPlus   \n3  TSSequencerPlus   \n4  TSSequencerPlus   \n5  TSSequencerPlus   \n6  TSSequencerPlus   \n7  TSSequencerPlus   \n8  TSSequencerPlus   \n9  TSSequencerPlus   \n\n                                                                                                                            hyperparams  \\\n0   {'d_model': 64, 'depth': 8, 'lstm_dropout': 0.1, 'dropout': 0.1, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n1   {'d_model': 64, 'depth': 2, 'lstm_dropout': 0.3, 'dropout': 0.2, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n2   {'d_model': 64, 'depth': 8, 'lstm_dropout': 0.2, 'dropout': 0.2, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n3   {'d_model': 32, 'depth': 2, 'lstm_dropout': 0.3, 'dropout': 0.1, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n4   {'d_model': 32, 'depth': 8, 'lstm_dropout': 0.3, 'dropout': 0.3, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n5   {'d_model': 64, 'depth': 4, 'lstm_dropout': 0.2, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n6   {'d_model': 64, 'depth': 8, 'lstm_dropout': 0.1, 'dropout': 0.3, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n7  {'d_model': 128, 'depth': 2, 'lstm_dropout': 0.1, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n8   {'d_model': 64, 'depth': 2, 'lstm_dropout': 0.1, 'dropout': 0.2, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n9   {'d_model': 64, 'depth': 8, 'lstm_dropout': 0.3, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}   \n\n   total params  train loss  valid loss  f1_score  time  epochs  max_lr  \n0       5970213    0.427612    0.422031  0.758592    23      25   0.001  \n1       5970213    0.427171    0.404420  0.753042    24      25   0.001  \n2       5970213    0.451165    0.418198  0.743834    25      25   0.001  \n3       5970213    0.451861    0.429594  0.739056    24      25   0.001  \n4       5970213    0.456144    0.441845  0.738355    23      25   0.001  \n5       5970213    0.460782    0.489009  0.734320    24      25   0.001  \n6       5970213    0.455294    0.450360  0.733868    24      25   0.001  \n7       5970213    0.462414    0.476504  0.724439    25      25   0.001  \n8       5970213    0.471159    0.466182  0.722720    24      25   0.001  \n9       5970213    0.454743    0.445658  0.722663    25      25   0.001  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>arch</th>\n      <th>hyperparams</th>\n      <th>total params</th>\n      <th>train loss</th>\n      <th>valid loss</th>\n      <th>f1_score</th>\n      <th>time</th>\n      <th>epochs</th>\n      <th>max_lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 8, 'lstm_dropout': 0.1, 'dropout': 0.1, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.427612</td>\n      <td>0.422031</td>\n      <td>0.758592</td>\n      <td>23</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 2, 'lstm_dropout': 0.3, 'dropout': 0.2, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.427171</td>\n      <td>0.404420</td>\n      <td>0.753042</td>\n      <td>24</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 8, 'lstm_dropout': 0.2, 'dropout': 0.2, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.451165</td>\n      <td>0.418198</td>\n      <td>0.743834</td>\n      <td>25</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 32, 'depth': 2, 'lstm_dropout': 0.3, 'dropout': 0.1, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.451861</td>\n      <td>0.429594</td>\n      <td>0.739056</td>\n      <td>24</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 32, 'depth': 8, 'lstm_dropout': 0.3, 'dropout': 0.3, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.456144</td>\n      <td>0.441845</td>\n      <td>0.738355</td>\n      <td>23</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 4, 'lstm_dropout': 0.2, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.460782</td>\n      <td>0.489009</td>\n      <td>0.734320</td>\n      <td>24</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 8, 'lstm_dropout': 0.1, 'dropout': 0.3, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.455294</td>\n      <td>0.450360</td>\n      <td>0.733868</td>\n      <td>24</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 128, 'depth': 2, 'lstm_dropout': 0.1, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.462414</td>\n      <td>0.476504</td>\n      <td>0.724439</td>\n      <td>25</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 2, 'lstm_dropout': 0.1, 'dropout': 0.2, 'mlp_ratio': 2, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.471159</td>\n      <td>0.466182</td>\n      <td>0.722720</td>\n      <td>24</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>TSSequencerPlus</td>\n      <td>{'d_model': 64, 'depth': 8, 'lstm_dropout': 0.3, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}</td>\n      <td>5970213</td>\n      <td>0.454743</td>\n      <td>0.445658</td>\n      <td>0.722663</td>\n      <td>25</td>\n      <td>25</td>\n      <td>0.001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"TSSequencerPlus \n {'d_model': 128, 'depth': 4, 'lstm_dropout': 0.2, 'dropout': 0.3, 'mlp_ratio': 4, 'n_layers': 4, 'hidden_size': 512, 'use_pe': True}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='20' class='' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      80.00% [20/25 00:19&lt;00:04]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2.540128</td>\n      <td>2.169359</td>\n      <td>0.085934</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2.174905</td>\n      <td>1.774207</td>\n      <td>0.057692</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.866275</td>\n      <td>1.594628</td>\n      <td>0.160659</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.626725</td>\n      <td>1.366895</td>\n      <td>0.171355</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.450552</td>\n      <td>1.334503</td>\n      <td>0.153336</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.337895</td>\n      <td>1.189772</td>\n      <td>0.300820</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.248308</td>\n      <td>1.191933</td>\n      <td>0.190904</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.177796</td>\n      <td>1.074227</td>\n      <td>0.288250</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.098360</td>\n      <td>1.075785</td>\n      <td>0.333118</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.036152</td>\n      <td>1.061854</td>\n      <td>0.301270</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.982702</td>\n      <td>0.956595</td>\n      <td>0.366159</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.922978</td>\n      <td>0.870730</td>\n      <td>0.384633</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.864681</td>\n      <td>0.868623</td>\n      <td>0.433415</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.833667</td>\n      <td>0.799910</td>\n      <td>0.388280</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.796826</td>\n      <td>0.693769</td>\n      <td>0.548093</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.736631</td>\n      <td>0.693286</td>\n      <td>0.524303</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.685573</td>\n      <td>0.618447</td>\n      <td>0.613698</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.635865</td>\n      <td>0.617825</td>\n      <td>0.611541</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.604506</td>\n      <td>0.593395</td>\n      <td>0.665550</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.568465</td>\n      <td>0.520277</td>\n      <td>0.651331</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table><p>\n\n    <div>\n      <progress value='4' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      8.00% [4/50 00:00&lt;00:00 0.5684]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with valid_loss value: 2.169358968734741.\nBetter model found at epoch 1 with valid_loss value: 1.7742068767547607.\nBetter model found at epoch 2 with valid_loss value: 1.5946276187896729.\nBetter model found at epoch 3 with valid_loss value: 1.366895079612732.\nBetter model found at epoch 4 with valid_loss value: 1.334502935409546.\nBetter model found at epoch 5 with valid_loss value: 1.1897718906402588.\nBetter model found at epoch 7 with valid_loss value: 1.0742267370224.\nBetter model found at epoch 9 with valid_loss value: 1.0618541240692139.\nBetter model found at epoch 10 with valid_loss value: 0.9565954208374023.\nBetter model found at epoch 11 with valid_loss value: 0.8707296252250671.\nBetter model found at epoch 12 with valid_loss value: 0.8686229586601257.\nBetter model found at epoch 13 with valid_loss value: 0.7999101877212524.\nBetter model found at epoch 14 with valid_loss value: 0.6937692761421204.\nBetter model found at epoch 15 with valid_loss value: 0.6932855844497681.\nBetter model found at epoch 16 with valid_loss value: 0.6184473633766174.\nBetter model found at epoch 17 with valid_loss value: 0.6178252100944519.\nBetter model found at epoch 18 with valid_loss value: 0.5933951139450073.\nBetter model found at epoch 19 with valid_loss value: 0.5202774405479431.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Finding optimal starting LR for the tuned model","metadata":{"id":"6rbjHIoL578Y"}},{"cell_type":"code","source":"learn = Learner(dls, RNNAttention(dls.vars, dls.c, dls.len, rnn_layers=3, hidden_size=1024, encoder_layers=3, rnn_dropout=0.2), metrics=[F1Score(average='macro')])\nlearn.lr_find()","metadata":{"id":"NQO8XzwxtbXv","colab":{"base_uri":"https://localhost:8080/","height":471},"executionInfo":{"status":"ok","timestamp":1706964830448,"user_tz":-360,"elapsed":39877,"user":{"displayName":"S.M. Hozaifa Hossain","userId":"03039388269630313999"}},"outputId":"7d143dc4-8418-4b1a-a0a6-b1b66ecc40bc","execution":{"iopub.status.busy":"2024-02-05T05:21:02.389755Z","iopub.status.idle":"2024-02-05T05:21:02.390217Z","shell.execute_reply.started":"2024-02-05T05:21:02.389969Z","shell.execute_reply":"2024-02-05T05:21:02.389988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tuning n_epochs and max_learning_rate","metadata":{"id":"_l9c7Rg56Bn2"}},{"cell_type":"code","source":"# Fixed model hyperparameters\nk = {'rnn_layers': 3, 'hidden_size': 1024, 'encoder_layers': 3, 'rnn_dropout': 0.2}\n\n# Define options for epochs and max_lr\nepochs_options = [75]\nbase_lr = 1.65e-5\ndel_lr = 5e-7\nmax_lrs = [base_lr]\n\nresults = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'f1_score', 'time', 'epochs', 'max_lr'])\n\nfor epochs in epochs_options:\n   for max_lr in max_lrs:\n       model = create_model(RNNAttention, dls=dls, **k)  # Create model within the loop\n       learn = Learner(dls, model, metrics=[F1Score(average='macro')])\n\n       print(model.__class__.__name__)\n       start = time.time()\n       learn.fit_one_cycle(epochs, max_lr)\n       elapsed = time.time() - start\n       vals = learn.recorder.values[-1]\n\n       results.loc[len(results)] = [\n           model.__class__.__name__,\n           k,\n           count_parameters(model),\n           vals[0],\n           vals[1],\n           vals[2],\n           int(elapsed),\n           epochs,\n           max_lr\n       ]\n       results.sort_values(by='f1_score', ascending=False, kind='stable', ignore_index=True, inplace=True)\n       clear_output()\n       display(results)","metadata":{"id":"zTC8r1iYs8v8","execution":{"iopub.status.busy":"2024-02-05T05:21:02.391863Z","iopub.status.idle":"2024-02-05T05:21:02.392611Z","shell.execute_reply.started":"2024-02-05T05:21:02.392378Z","shell.execute_reply":"2024-02-05T05:21:02.392398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion:\n\n\n1.   RNNPlus: n_layers = 4, hidden_size = 1024, epochs=75, max_lr=2.12e-4\n2.   RNNAttention:\n`rnn_layers_options = [3]  \nhidden_size_options = [1024]  \nencoder_layers_options = [3]  \ndropout_options = [0.2]\nmax_lr=1.65e-5 \nepochs=75`\n\n7. InceptionTime\n7. TSSequencerPlus\n9. TransformerRNNPlus\n10. TSTPlus\n11. PatchTST\n12. ResNet\n13. xresnet1d34_deeperplus\n\n\n\n\n","metadata":{"id":"NAl9N1g4xZIj"}},{"cell_type":"code","source":"","metadata":{"id":"rwv7B-KQ4HGe"},"execution_count":null,"outputs":[]}]}